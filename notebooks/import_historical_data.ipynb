{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "sys.path.insert(0, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5477225575051661"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data for one stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_df = pd.read_csv('../data/price-volume-data-for-all-us-stocks-etfs/Stocks/ph.us.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>OpenInt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7944</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>140.04</td>\n",
       "      <td>140.35</td>\n",
       "      <td>137.65</td>\n",
       "      <td>139.07</td>\n",
       "      <td>567140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Open    High     Low   Close  Volume  OpenInt\n",
       "7944  2017-01-05  140.04  140.35  137.65  139.07  567140        0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph_df[ph_df.Date == '2017-01-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>krus</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blmn</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frgi</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ruth</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eat</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>rop</td>\n",
       "      <td>industrial conglomerates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>rost</td>\n",
       "      <td>retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>so</td>\n",
       "      <td>utilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>ual</td>\n",
       "      <td>airlines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>vno</td>\n",
       "      <td>real estate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    symbol                  industry\n",
       "0     krus                restaurant\n",
       "1     blmn                restaurant\n",
       "2     frgi                restaurant\n",
       "3     ruth                restaurant\n",
       "4      eat                restaurant\n",
       "..     ...                       ...\n",
       "195    rop  industrial conglomerates\n",
       "196   rost                    retail\n",
       "197     so                 utilities\n",
       "198    ual                  airlines\n",
       "199    vno               real estate\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_to_indsutry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run through stocks we pulled data from IEX for. Update the .csv file with this historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def add_historic_data_to_current_csv():\n",
    "#     current_data_file_path = '../data/historical_etf_data'\n",
    "    current_data_file_path = '../data/historical_stock_data'\n",
    "    augmented_data_file_path = '../data/updated_historical_stock_and_etf_data'\n",
    "#     historic_data_file_path = '../data/price-volume-data-for-all-us-stocks-etfs/ETFs'\n",
    "    historic_data_file_path = '../data/price-volume-data-for-all-us-stocks-etfs/Stocks'    \n",
    "\n",
    "    for file in glob.glob(f'{current_data_file_path}/*.csv'):\n",
    "        print(f'File = {file}')\n",
    "        stock_name = file.rsplit(\"/\")[-1].split('_')[0].lower() # note: store all stock names as uppercase\n",
    "        \n",
    "        # find the stock name in historical kaggle dataa\n",
    "        for historical_file in glob.glob(f'{historic_data_file_path}/*.txt'):\n",
    "            historical_stock_name = historical_file.split(\"/\")[-1].split(\".\")[0]\n",
    "            \n",
    "            if stock_name == historical_stock_name:\n",
    "                print('found historical stock', historical_stock_name)\n",
    "                # read in current data\n",
    "                current_stock_data = pd.read_csv(f\"{file}\")\n",
    "                historical_stock_data = pd.read_csv(f\"{historical_file}\")\n",
    "                historical_stock_data.columns = map(str.lower, historical_stock_data.columns)\n",
    "\n",
    "                oldest_date_of_new_data = current_stock_data.date.min()\n",
    "\n",
    "                # get the new data we don't have yet\n",
    "                historical_stock_data = historical_stock_data[historical_stock_data.date < oldest_date_of_new_data]\n",
    "                historical_stock_data.drop('openint', inplace=True, axis=1)\n",
    "\n",
    "\n",
    "                # concat historical with current data\n",
    "                combined_stock_df = pd.concat([current_stock_data, historical_stock_data])\n",
    "                most_recent_date = combined_stock_df.date.max()\n",
    "                most_recent_year, most_recent_month, most_recent_day = most_recent_date.split('-')\n",
    "\n",
    "                oldest_date = combined_stock_df.date.min()\n",
    "                oldest_year, oldest_month, oldest_day = oldest_date.split('-')\n",
    "                \n",
    "               # delete the old file only if we haven't  updated it\n",
    "                delete_old_csv(stock_name, augmented_data_file_path)\n",
    "                \n",
    "                # save the file\n",
    "                combined_stock_df.to_csv(f'{augmented_data_file_path}/{stock_name.lower()}_{int(oldest_year)}-{int(oldest_month)}-{int(oldest_day)}_to_{int(most_recent_year)}-{int(most_recent_month)}-{int(most_recent_day)}.csv',\n",
    "                                         index=False)\n",
    "             \n",
    "                break\n",
    "\n",
    "        # # if we don't have historical data , save the original data into the augmented folder\n",
    "        # if os.path.isfile(f'{augmented_data_file_path}/{stock_name.lower()}_{int(oldest_year)}-{int(oldest_month)}-{int(oldest_day)}_to_{int(most_recent_year)}-{int(most_recent_month)}-{int(most_recent_day)}.csv'):\n",
    "        #     pass\n",
    "        # else:\n",
    "        #     current_stock_data = pd.read_csv(f\"{file}\")\n",
    "        #     current_stock_data.to_csv(f\"{augmented_data_file_path}/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_old_csv(stock_name, folder_path):\n",
    "    for file in glob.glob(f'{folder_path}/*.csv'):\n",
    "        if stock_name in file:\n",
    "            os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File = ../data/historical_stock_data/are_2017-01-03_to_2020-4-27.csv\n",
      "found historical stock are\n",
      "File = ../data/historical_stock_data/ce_2017-01-03_to_2020-4-27.csv\n",
      "found historical stock ce\n",
      "File = ../data/historical_stock_data/ual_2017-01-03_to_2020-4-27.csv\n",
      "found historical stock ual\n",
      "File = ../data/historical_stock_data/atvi_2017-01-03_to_2020-4-27.csv\n",
      "found historical stock atvi\n",
      "File = ../data/historical_stock_data/adbe_2017-01-03_to_2020-4-27.csv\n",
      "found historical stock adbe\n",
      "File = ../data/historical_stock_data/ph_2017-01-03_to_2020-4-27.csv\n",
      "found historical stock ph\n",
      "File = ../data/historical_stock_data/pg_2017-01-03_to_2020-4-27.csv\n",
      "found historical stock pg\n",
      "File = ../data/historical_stock_data/peg_2017-01-03_to_2020-4-27.csv\n",
      "found historical stock peg\n",
      "File = ../data/historical_stock_data/rop_2017-01-03_to_2020-4-27.csv\n",
      "found historical stock rop\n",
      "File = ../data/historical_stock_data/lb_2017-01-03_to_2020-4-27.csv\n",
      "found historical stock lb\n",
      "File = ../data/historical_stock_data/pnr_2017-01-03_to_2020-4-27.csv\n",
      "found historical stock pnr\n",
      "File = ../data/historical_stock_data/efx_2017-01-03_to_2020-4-27.csv\n",
      "found historical stock efx\n",
      "File = ../data/historical_stock_data/cern_2017-1-1_to_2020-4-27.csv\n",
      "found historical stock cern\n",
      "File = ../data/historical_stock_data/rost_2017-01-03_to_2020-4-27.csv\n",
      "found historical stock rost\n",
      "File = ../data/historical_stock_data/pvh_2017-01-03_to_2020-4-27.csv\n",
      "found historical stock pvh\n",
      "File = ../data/historical_stock_data/qqq_2017-1-1_to_2020-4-27.csv\n",
      "File = ../data/historical_stock_data/vno_2017-01-03_to_2020-4-27.csv\n",
      "found historical stock vno\n",
      "File = ../data/historical_stock_data/ni_2017-01-03_to_2020-4-27.csv\n",
      "found historical stock ni\n",
      "File = ../data/historical_stock_data/so_2017-01-03_to_2020-4-27.csv\n",
      "found historical stock so\n",
      "File = ../data/historical_stock_data/eqix_2017-01-03_to_2020-4-27.csv\n",
      "found historical stock eqix\n",
      "File = ../data/historical_stock_data/emr_2017-01-03_to_2020-4-27.csv\n",
      "found historical stock emr\n",
      "File = ../data/historical_stock_data/bac_2017-01-03_to_2020-4-27.csv\n",
      "found historical stock bac\n"
     ]
    }
   ],
   "source": [
    "add_historic_data_to_current_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('daily-trading-nJ43NNNI-py3.7': venv)",
   "language": "python",
   "name": "python37064bitdailytradingnj43nnnipy37venvd9db9359ec934f90b15f4732101b653e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
