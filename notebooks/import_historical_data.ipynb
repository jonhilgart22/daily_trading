{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5477225575051661"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run through stocks we pulled data from IEX for. Update the .csv file with this historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def add_historic_data_to_current_csv():\n",
    "    current_data_file_path = '../data/historical_etf_data'\n",
    "#    current_data_file_path = '../data/historical_stock_data'\n",
    "    augmented_data_file_path = '../data/updated_historical_stock_and_etf_data'\n",
    "    historic_data_file_path = '../data/price-volume-data-for-all-us-stocks-etfs/ETFs'\n",
    "#    historic_data_file_path = '../data/price-volume-data-for-all-us-stocks-etfs/Stocks'    \n",
    "\n",
    "    for file in glob.glob(f'{current_data_file_path}/*.csv'):\n",
    "        print(f'File = {file}')\n",
    "        stock_name = file.rsplit(\"/\")[-1].split('_')[0].lower() # note: store all stock names as uppercase\n",
    "        found_historical_stock = False\n",
    "        # find the stock name in historical kaggle dataa\n",
    "        for historical_file in glob.glob(f'{historic_data_file_path}/*.txt'):\n",
    "            historical_stock_name = historical_file.split(\"/\")[-1].split(\".\")[0]\n",
    "            \n",
    "            if stock_name == historical_stock_name:\n",
    "                print('found historical stock', historical_stock_name)\n",
    "                # read in current data\n",
    "                current_stock_data = pd.read_csv(f\"{file}\")\n",
    "                print(historical_file, 'historical_file')\n",
    "                historical_stock_data = pd.read_csv(f\"{historical_file}\")\n",
    "                historical_stock_data.columns = map(str.lower, historical_stock_data.columns)\n",
    "\n",
    "                oldest_date_of_new_data = current_stock_data.date.min()\n",
    "\n",
    "                # get the new data we don't have yet\n",
    "                historical_stock_data = historical_stock_data[historical_stock_data.date < oldest_date_of_new_data]\n",
    "                historical_stock_data.drop('openint', inplace=True, axis=1)\n",
    "\n",
    "\n",
    "                # concat historical with current data\n",
    "                combined_stock_df = pd.concat([current_stock_data, historical_stock_data])\n",
    "                most_recent_date = combined_stock_df.date.max()\n",
    "                most_recent_year, most_recent_month, most_recent_day = most_recent_date.split('-')\n",
    "\n",
    "                oldest_date = combined_stock_df.date.min()\n",
    "                oldest_year, oldest_month, oldest_day = oldest_date.split('-')\n",
    "                \n",
    "               # delete the old file only if we haven't  updated it\n",
    "                delete_old_csv(stock_name, augmented_data_file_path)\n",
    "                \n",
    "                # save the file\n",
    "                combined_stock_df.to_csv(f'{augmented_data_file_path}/{stock_name.lower()}_{int(oldest_year)}-{int(oldest_month)}-{int(oldest_day)}_to_{int(most_recent_year)}-{int(most_recent_month)}-{int(most_recent_day)}.csv',\n",
    "                                         index=False)\n",
    "                found_historical_stock = True\n",
    "             \n",
    "                break\n",
    "\n",
    "        # # if we don't have historical data , save the original data into the augmented folder\n",
    "        if not found_historical_stock:\n",
    "            print(file.split(\"/\")[-1])\n",
    "\n",
    "            current_stock_data = pd.read_csv(f\"{file}\")\n",
    "            stock_name = file.split(\"/\")[-1]\n",
    "            \n",
    "            current_stock_data.to_csv(f\"{augmented_data_file_path}/{stock_name}\",\n",
    "                                             index=False)\n",
    "        # if os.path.isfile(f'{augmented_data_file_path}/{stock_name.lower()}_{int(oldest_year)}-{int(oldest_month)}-{int(oldest_day)}_to_{int(most_recent_year)}-{int(most_recent_month)}-{int(most_recent_day)}.csv'):\n",
    "        #     pass\n",
    "        # else:\n",
    "        #     current_stock_data = pd.read_csv(f\"{file}\")\n",
    "        #     current_stock_data.to_csv(f\"{augmented_data_file_path}/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_old_csv(stock_name, folder_path):\n",
    "    for file in glob.glob(f'{folder_path}/*.csv'):\n",
    "        if stock_name in file:\n",
    "            os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File = ../data/historical_etf_data/ibuy_2017-1-1_to_2020-6-26.csv\n",
      "ibuy_2017-1-1_to_2020-6-26.csv\n",
      "File = ../data/historical_etf_data/dia_2017-1-1_to_2020-6-26.csv\n",
      "dia_2017-1-1_to_2020-6-26.csv\n",
      "File = ../data/historical_etf_data/bjk_2017-1-1_to_2020-6-26.csv\n",
      "bjk_2017-1-1_to_2020-6-26.csv\n",
      "File = ../data/historical_etf_data/hpt_2017-1-1_to_2020-4-29.csv\n",
      "hpt_2017-1-1_to_2020-4-29.csv\n",
      "File = ../data/historical_etf_data/pbj_2017-1-1_to_2020-6-26.csv\n",
      "pbj_2017-1-1_to_2020-6-26.csv\n",
      "File = ../data/historical_etf_data/spy_2017-1-1_to_2020-6-26.csv\n",
      "spy_2017-1-1_to_2020-6-26.csv\n",
      "File = ../data/historical_etf_data/sh_2017-01-03_to_2020-6-26.csv\n",
      "sh_2017-01-03_to_2020-6-26.csv\n",
      "File = ../data/historical_etf_data/uso_2017-1-1_to_2020-6-26.csv\n",
      "uso_2017-1-1_to_2020-6-26.csv\n",
      "File = ../data/historical_etf_data/vti_2017-1-1_to_2020-6-26.csv\n",
      "vti_2017-1-1_to_2020-6-26.csv\n",
      "File = ../data/historical_etf_data/pej_2017-1-1_to_2020-6-26.csv\n",
      "pej_2017-1-1_to_2020-6-26.csv\n",
      "File = ../data/historical_etf_data/vfh_2017-1-1_to_2020-6-26.csv\n",
      "vfh_2017-1-1_to_2020-6-26.csv\n",
      "File = ../data/historical_etf_data/qqq_2017-1-1_to_2020-6-26.csv\n",
      "qqq_2017-1-1_to_2020-6-26.csv\n",
      "File = ../data/historical_etf_data/xrt_2017-1-1_to_2020-6-26.csv\n",
      "xrt_2017-1-1_to_2020-6-26.csv\n",
      "File = ../data/historical_etf_data/vgk_2017-1-1_to_2020-6-26.csv\n",
      "vgk_2017-1-1_to_2020-6-26.csv\n",
      "File = ../data/historical_etf_data/tlt_2017-1-1_to_2020-6-26.csv\n",
      "tlt_2017-1-1_to_2020-6-26.csv\n",
      "File = ../data/historical_etf_data/inn_2017-1-1_to_2020-6-26.csv\n",
      "inn_2017-1-1_to_2020-6-26.csv\n",
      "File = ../data/historical_etf_data/iwm_2017-1-1_to_2020-6-26.csv\n",
      "iwm_2017-1-1_to_2020-6-26.csv\n"
     ]
    }
   ],
   "source": [
    "add_historic_data_to_current_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "autocomplete-lambda",
   "language": "python",
   "name": "autocomplete-lambda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
